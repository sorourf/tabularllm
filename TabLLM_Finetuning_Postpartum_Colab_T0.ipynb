{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# TabLLM Fine-Tuning for Postpartum Depression Classification\n",
    "\n",
    "This notebook implements the fine-tuning approach from the TabLLM paper using **BigScience T0** models.\n",
    "\n",
    "**Paper**: [TabLLM: Few-shot Classification of Tabular Data with Large Language Models](https://arxiv.org/pdf/2210.10723)\n",
    "\n",
    "**GitHub**: [https://github.com/clinicalml/TabLLM](https://github.com/clinicalml/TabLLM)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook uses the **bigscience/T0_3B** model (as per TabLLM paper) with parameter-efficient fine-tuning.\n",
    "\n",
    "**Model Options**:\n",
    "- `bigscience/T0_3B` (3 billion parameters) - Recommended for Colab\n",
    "- `bigscience/T0` or `bigscience/T0pp` (11 billion parameters) - Requires A100 GPU\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- **Runtime**: GPU (V100 or A100 recommended for T0_3B)\n",
    "- **RAM**: High-RAM runtime **required**\n",
    "- **Estimated Time**: 45-90 minutes for full training\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Enable High-RAM GPU**: Runtime → Change runtime type → GPU + High-RAM\n",
    "2. Upload dataset files or mount Google Drive\n",
    "3. Run all cells in order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers==4.30.0 datasets==2.14.0 accelerate==0.20.0 \n",
    "!pip install -q sentencepiece protobuf scikit-learn pandas numpy\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM,\n",
    "    Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_upload"
   },
   "source": [
    "## 2. Data Upload\n",
    "\n",
    "**Option 1**: Upload files directly\n",
    "- Click the folder icon in the left sidebar\n",
    "- Upload `train_postpartum_depression.csv` and `test_postpartum_depression.csv`\n",
    "\n",
    "**Option 2**: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Option 2: Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set data directory (adjust path as needed)\n",
    "DATA_DIR = '/content'  # If uploaded directly\n",
    "# DATA_DIR = '/content/drive/MyDrive/your_folder'  # If using Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "template_def"
   },
   "source": [
    "## 3. Template Definition\n",
    "\n",
    "Define TabLLM templates for text serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "templates"
   },
   "outputs": [],
   "source": [
    "# Define feature names for template\n",
    "postpartum_feature_names = [\n",
    "    ('age', 'age range'),\n",
    "    ('feeling_sad_or_tearful', 'feeling sad or tearful'),\n",
    "    ('irritable_towards_baby_partner', 'irritable towards baby and partner'),\n",
    "    ('trouble_sleeping_at_night', 'trouble sleeping at night'),\n",
    "    ('problems_concentrating_or_making_decision', 'problems concentrating or making decision'),\n",
    "    ('overeating_or_loss_of_appetite', 'overeating or loss of appetite'),\n",
    "    ('feeling_of_guilt', 'feeling of guilt'),\n",
    "    ('problems_of_bonding_with_baby', 'problems of bonding with baby'),\n",
    "    ('suicide_attempt', 'suicide attempt history'),\n",
    "]\n",
    "\n",
    "# Create template\n",
    "template_parts = [f\"- {desc}: {{{var}}}\" for var, desc in postpartum_feature_names]\n",
    "template = \"\\n\".join(template_parts)\n",
    "\n",
    "print(\"Template:\")\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "helper_functions"
   },
   "outputs": [],
   "source": [
    "def clean_note(note):\n",
    "    \"\"\"Clean generated note text\"\"\"\n",
    "    note = re.sub(r\"[ \\t]+\", \" \", note)\n",
    "    note = re.sub(\"\\n\\n\\n+\", \"\\n\\n\", note)\n",
    "    note = re.sub(r\"^[ \\t]+\", \"\", note)\n",
    "    note = re.sub(r\"\\n[ \\t]+\", \"\\n\", note)\n",
    "    note = re.sub(r\"[ \\t]$\", \"\", note)\n",
    "    note = re.sub(r\"[ \\t]\\n\", \"\\n\", note)\n",
    "    return note.strip()\n",
    "\n",
    "\n",
    "def serialize_row(row, template_str):\n",
    "    \"\"\"Serialize a single row to text\"\"\"\n",
    "    text = template_str\n",
    "    for var, _ in postpartum_feature_names:\n",
    "        value = str(row[var]) if var in row else \"N/A\"\n",
    "        text = text.replace(f\"{{{var}}}\", value)\n",
    "    return clean_note(text)\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(data_dir):\n",
    "    \"\"\"Load and preprocess postpartum depression dataset\"\"\"\n",
    "    print(\"Loading dataset...\")\n",
    "    \n",
    "    train_df = pd.read_csv(f\"{data_dir}/train_postpartum_depression.csv\")\n",
    "    test_df = pd.read_csv(f\"{data_dir}/test_postpartum_depression.csv\")\n",
    "    \n",
    "    print(f\"Train samples: {len(train_df)}, Test samples: {len(test_df)}\")\n",
    "    \n",
    "    # Column mapping\n",
    "    column_mapping = {\n",
    "        'timestamp': 'timestamp',\n",
    "        'age': 'age',\n",
    "        'feeling sad or tearful': 'feeling_sad_or_tearful',\n",
    "        'irritable towards baby & partner': 'irritable_towards_baby_partner',\n",
    "        'trouble sleeping at night': 'trouble_sleeping_at_night',\n",
    "        'problems concentrating or making decision': 'problems_concentrating_or_making_decision',\n",
    "        'overeating or loss of appetite': 'overeating_or_loss_of_appetite',\n",
    "        'feeling anxious': 'label',\n",
    "        'feeling of guilt': 'feeling_of_guilt',\n",
    "        'problems of bonding with baby': 'problems_of_bonding_with_baby',\n",
    "        'suicide attempt': 'suicide_attempt'\n",
    "    }\n",
    "    \n",
    "    train_df = train_df.rename(columns=column_mapping)\n",
    "    test_df = test_df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Drop timestamp\n",
    "    train_df = train_df.drop(columns=['timestamp'])\n",
    "    test_df = test_df.drop(columns=['timestamp'])\n",
    "    \n",
    "    # Convert labels\n",
    "    label_mapping = {'Yes': 'Yes', 'No': 'No'}\n",
    "    train_df['label'] = train_df['label'].map(label_mapping).fillna('No')\n",
    "    test_df['label'] = test_df['label'].map(label_mapping).fillna('No')\n",
    "    \n",
    "    print(f\"Train label distribution:\\n{train_df['label'].value_counts()}\")\n",
    "    print(f\"Test label distribution:\\n{test_df['label'].value_counts()}\")\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_processing"
   },
   "source": [
    "## 4. Data Loading and Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df, test_df = load_and_preprocess_data(DATA_DIR)\n",
    "\n",
    "# Serialize to text\n",
    "print(\"\\nSerializing data to text...\")\n",
    "train_texts = [serialize_row(row, template) for _, row in train_df.iterrows()]\n",
    "test_texts = [serialize_row(row, template) for _, row in test_df.iterrows()]\n",
    "\n",
    "print(f\"\\nExample serialized text:\\n{train_texts[0]}\")\n",
    "print(f\"\\nLabel: {train_df.iloc[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_class"
   },
   "source": [
    "## 5. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset"
   },
   "outputs": [],
   "source": [
    "class PostpartumDataset(Dataset):\n",
    "    \"\"\"Dataset for postpartum depression classification\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # T0 models don't need explicit task prefix\n",
    "        # They were instruction-tuned and can handle raw text\n",
    "        input_text = text\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize label\n",
    "        labels = self.tokenizer(\n",
    "            label,\n",
    "            max_length=10,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': labels['input_ids'].squeeze()\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "print(\"Loading tokenizer and model...\")\n",
    "print(\"⚠️ This will download ~12GB for T0_3B. Please wait...\")\n",
    "\n",
    "# MODEL OPTIONS (uncomment one):\n",
    "MODEL_NAME = \"bigscience/T0_3B\"  # 3B params - Works on V100/A100 with High-RAM\n",
    "# MODEL_NAME = \"bigscience/T0pp\"   # 11B params - Requires A100 40GB+\n",
    "# MODEL_NAME = \"bigscience/T0\"     # 11B params - Requires A100 40GB+\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PostpartumDataset(\n",
    "    train_texts,\n",
    "    train_df['label'].tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = PostpartumDataset(\n",
    "    test_texts,\n",
    "    test_df['label'].tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_training"
   },
   "source": [
    "## 6. Model Fine-Tuning\n",
    "\n",
    "Using **BigScience T0** model as per TabLLM paper.\n",
    "\n",
    "**Note**: T0_3B requires ~12GB GPU memory + High-RAM runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_model"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "print(\"Loading T0 model (this may take a few minutes)...\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,  # Use bf16 as per TabLLM paper config\n",
    "    device_map=\"auto\"  # Automatically distribute across available devices\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Model loaded on {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_args"
   },
   "outputs": [],
   "source": [
    "# Training arguments (adjusted for T0_3B)\n",
    "OUTPUT_DIR = \"/content/tabllm_t0_finetuned\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=5,  # Fewer epochs for large model\n",
    "    per_device_train_batch_size=4,  # Smaller batch for T0_3B\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,  # Effective batch size = 4*4=16\n",
    "    learning_rate=3e-5,  # Lower LR for large pre-trained model\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    logging_steps=20,\n",
    "    eval_steps=100,\n",
    "    save_steps=200,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    bf16=True,  # Use BF16 as per TabLLM config\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Gradient accumulation: {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"BF16: {training_args.bf16}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trainer"
   },
   "outputs": [],
   "source": [
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized\")\n",
    "print(\"\\n⚠️ Training will take 45-90 minutes on V100/A100...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train"
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Starting training with T0_3B model...\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Training loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(f\"{OUTPUT_DIR}/final_model\")\n",
    "tokenizer.save_pretrained(f\"{OUTPUT_DIR}/final_model\")\n",
    "print(f\"Model saved to {OUTPUT_DIR}/final_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## 7. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict"
   },
   "outputs": [],
   "source": [
    "def predict_batch(model, tokenizer, texts, batch_size=8, device='cuda'):\n",
    "    \"\"\"Make predictions on a batch of texts\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        # Prepare inputs (no task prefix needed for T0)\n",
    "        encoded = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "        \n",
    "        # Generate predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **encoded,\n",
    "                max_length=10,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        # Decode predictions\n",
    "        batch_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        predictions.extend(batch_preds)\n",
    "        \n",
    "        if (i // batch_size + 1) % 10 == 0:\n",
    "            print(f\"Processed {i+len(batch_texts)}/{len(texts)} samples\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Make predictions on test set\n",
    "print(\"Making predictions on test set...\")\n",
    "predictions = predict_batch(model, tokenizer, test_texts, device=device)\n",
    "\n",
    "# Convert predictions to binary\n",
    "def parse_prediction(pred):\n",
    "    pred = pred.strip().lower()\n",
    "    return 1 if 'yes' in pred else 0\n",
    "\n",
    "pred_binary = [parse_prediction(p) for p in predictions]\n",
    "true_binary = [1 if label == 'Yes' else 0 for label in test_df['label'].tolist()]\n",
    "\n",
    "print(f\"\\nExample predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"True: {test_df.iloc[i]['label']}, Predicted: {predictions[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "metrics"
   },
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_binary, pred_binary)\n",
    "precision = precision_score(true_binary, pred_binary, average='binary', zero_division=0)\n",
    "recall = recall_score(true_binary, pred_binary, average='binary', zero_division=0)\n",
    "f1 = f1_score(true_binary, pred_binary, average='binary', zero_division=0)\n",
    "\n",
    "try:\n",
    "    auc_roc = roc_auc_score(true_binary, pred_binary)\n",
    "except:\n",
    "    auc_roc = 0.5\n",
    "\n",
    "cm = confusion_matrix(true_binary, pred_binary)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TABLLM FINE-TUNING RESULTS (T0_3B) - Postpartum Depression\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "print(f\"AUC-ROC:   {auc_roc:.4f} ({auc_roc*100:.2f}%)\")\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"TN: {cm[0][0]}, FP: {cm[0][1]}\")\n",
    "print(f\"FN: {cm[1][0]}, TP: {cm[1][1]}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(true_binary, pred_binary, target_names=['No Anxiety', 'Anxiety']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_results"
   },
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save"
   },
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "results = {\n",
    "    'model': MODEL_NAME,\n",
    "    'metrics': {\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'f1_score': float(f1),\n",
    "        'auc_roc': float(auc_roc)\n",
    "    },\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'classification_report': classification_report(true_binary, pred_binary, output_dict=True)\n",
    "}\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/finetuning_metrics.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'true_label': test_df['label'].tolist(),\n",
    "    'predicted_label': predictions,\n",
    "    'true_binary': true_binary,\n",
    "    'predicted_binary': pred_binary\n",
    "})\n",
    "predictions_df.to_csv(f\"{OUTPUT_DIR}/finetuning_predictions.csv\", index=False)\n",
    "\n",
    "print(f\"Results saved to {OUTPUT_DIR}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"- {OUTPUT_DIR}/final_model/ (trained model)\")\n",
    "print(f\"- {OUTPUT_DIR}/finetuning_metrics.json\")\n",
    "print(f\"- {OUTPUT_DIR}/finetuning_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 9. Download Results\n",
    "\n",
    "⚠️ **Note**: Model is ~12GB. Consider saving only metrics/predictions if space is limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_files"
   },
   "outputs": [],
   "source": [
    "# Option 1: Zip only metrics and predictions (small)\n",
    "!zip -r /content/tabllm_results_metrics_only.zip {OUTPUT_DIR}/*.json {OUTPUT_DIR}/*.csv\n",
    "\n",
    "print(\"Metrics and predictions zipped!\")\n",
    "print(\"Download 'tabllm_results_metrics_only.zip' from the files panel\")\n",
    "\n",
    "# Option 2: Zip everything including model (WARNING: ~12GB)\n",
    "# !zip -r /content/tabllm_results_full.zip {OUTPUT_DIR}\n",
    "\n",
    "# Option 3: Copy to Google Drive\n",
    "# !cp -r {OUTPUT_DIR} /content/drive/MyDrive/tabllm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## Model Information\n",
    "\n",
    "### BigScience T0 Models\n",
    "\n",
    "The TabLLM paper uses **T0** models which are instruction-tuned variants of T5:\n",
    "\n",
    "| Model | Parameters | GPU Required | Training Time |\n",
    "|-------|-----------|--------------|---------------|\n",
    "| `bigscience/T0_3B` | 3B | V100/A100 + High-RAM | 45-90 min |\n",
    "| `bigscience/T0pp` | 11B | A100 40GB+ | 2-4 hours |\n",
    "| `bigscience/T0` | 11B | A100 40GB+ | 2-4 hours |\n",
    "\n",
    "### T0 vs T5\n",
    "\n",
    "**T0 advantages**:\n",
    "- Instruction-tuned on diverse NLP tasks\n",
    "- Better zero/few-shot performance\n",
    "- As used in TabLLM paper\n",
    "\n",
    "**T5 advantages** (for comparison):\n",
    "- Smaller models available (t5-small, t5-base)\n",
    "- Faster training on limited hardware\n",
    "- Lower memory requirements\n",
    "\n",
    "### Alternative: T5 Models\n",
    "\n",
    "If T0_3B doesn't fit in memory, you can try:\n",
    "```python\n",
    "MODEL_NAME = \"t5-base\"  # 220M params - Works on T4\n",
    "MODEL_NAME = \"t5-large\" # 770M params - Works on V100\n",
    "```\n",
    "\n",
    "Performance may be 2-5% lower than T0, but still competitive.\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "**Out of Memory with T0_3B**:\n",
    "- Enable High-RAM runtime\n",
    "- Reduce batch size to 2\n",
    "- Increase gradient accumulation steps\n",
    "- Try t5-large instead\n",
    "\n",
    "**Slow Training**:\n",
    "- Verify BF16 is enabled\n",
    "- Check GPU utilization\n",
    "- Reduce max_length if possible\n",
    "\n",
    "## References\n",
    "\n",
    "- [TabLLM Paper](https://arxiv.org/pdf/2210.10723)\n",
    "- [T0 Paper](https://arxiv.org/abs/2110.08207)\n",
    "- [BigScience T0 Models](https://huggingface.co/bigscience/T0)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
