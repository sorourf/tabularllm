{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# TabLLM Fine-Tuning for Postpartum Depression Classification\n",
    "\n",
    "This notebook implements the fine-tuning approach from the TabLLM paper for postpartum depression classification.\n",
    "\n",
    "**Paper**: [TabLLM: Few-shot Classification of Tabular Data with Large Language Models](https://arxiv.org/pdf/2210.10723)\n",
    "\n",
    "**GitHub**: [https://github.com/clinicalml/TabLLM](https://github.com/clinicalml/TabLLM)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook will:\n",
    "1. Install required dependencies\n",
    "2. Load and preprocess the postpartum depression dataset\n",
    "3. Convert tabular data to text using TabLLM templates\n",
    "4. Fine-tune a T5-based model with parameter-efficient training (IA3)\n",
    "5. Evaluate on test set\n",
    "6. Save results and model\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- **Runtime**: GPU (T4, V100, or A100 recommended)\n",
    "- **RAM**: High-RAM runtime recommended\n",
    "- **Estimated Time**: 30-60 minutes for full training\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. Upload your dataset files to Colab or mount Google Drive\n",
    "2. Select GPU runtime: Runtime → Change runtime type → GPU\n",
    "3. Run all cells in order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers==4.30.0 datasets==2.14.0 accelerate==0.20.0 \n",
    "!pip install -q sentencepiece protobuf scikit-learn pandas numpy\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    T5Tokenizer, T5ForConditionalGeneration,\n",
    "    Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_upload"
   },
   "source": [
    "## 2. Data Upload\n",
    "\n",
    "**Option 1**: Upload files directly\n",
    "- Click the folder icon in the left sidebar\n",
    "- Upload `train_postpartum_depression.csv` and `test_postpartum_depression.csv`\n",
    "\n",
    "**Option 2**: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Option 2: Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set data directory (adjust path as needed)\n",
    "DATA_DIR = '/content'  # If uploaded directly\n",
    "# DATA_DIR = '/content/drive/MyDrive/your_folder'  # If using Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "template_def"
   },
   "source": [
    "## 3. Template Definition\n",
    "\n",
    "Define TabLLM templates for text serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "templates"
   },
   "outputs": [],
   "source": [
    "# Define feature names for template\n",
    "postpartum_feature_names = [\n",
    "    ('age', 'age range'),\n",
    "    ('feeling_sad_or_tearful', 'feeling sad or tearful'),\n",
    "    ('irritable_towards_baby_partner', 'irritable towards baby and partner'),\n",
    "    ('trouble_sleeping_at_night', 'trouble sleeping at night'),\n",
    "    ('problems_concentrating_or_making_decision', 'problems concentrating or making decision'),\n",
    "    ('overeating_or_loss_of_appetite', 'overeating or loss of appetite'),\n",
    "    ('feeling_of_guilt', 'feeling of guilt'),\n",
    "    ('problems_of_bonding_with_baby', 'problems of bonding with baby'),\n",
    "    ('suicide_attempt', 'suicide attempt history'),\n",
    "]\n",
    "\n",
    "# Create template\n",
    "template_parts = [f\"- {desc}: {{{var}}}\" for var, desc in postpartum_feature_names]\n",
    "template = \"\\n\".join(template_parts)\n",
    "\n",
    "print(\"Template:\")\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "helper_functions"
   },
   "outputs": [],
   "source": [
    "def clean_note(note):\n",
    "    \"\"\"Clean generated note text\"\"\"\n",
    "    note = re.sub(r\"[ \\t]+\", \" \", note)\n",
    "    note = re.sub(\"\\n\\n\\n+\", \"\\n\\n\", note)\n",
    "    note = re.sub(r\"^[ \\t]+\", \"\", note)\n",
    "    note = re.sub(r\"\\n[ \\t]+\", \"\\n\", note)\n",
    "    note = re.sub(r\"[ \\t]$\", \"\", note)\n",
    "    note = re.sub(r\"[ \\t]\\n\", \"\\n\", note)\n",
    "    return note.strip()\n",
    "\n",
    "\n",
    "def serialize_row(row, template_str):\n",
    "    \"\"\"Serialize a single row to text\"\"\"\n",
    "    text = template_str\n",
    "    for var, _ in postpartum_feature_names:\n",
    "        value = str(row[var]) if var in row else \"N/A\"\n",
    "        text = text.replace(f\"{{{var}}}\", value)\n",
    "    return clean_note(text)\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(data_dir):\n",
    "    \"\"\"Load and preprocess postpartum depression dataset\"\"\"\n",
    "    print(\"Loading dataset...\")\n",
    "    \n",
    "    train_df = pd.read_csv(f\"{data_dir}/train_postpartum_depression.csv\")\n",
    "    test_df = pd.read_csv(f\"{data_dir}/test_postpartum_depression.csv\")\n",
    "    \n",
    "    print(f\"Train samples: {len(train_df)}, Test samples: {len(test_df)}\")\n",
    "    \n",
    "    # Column mapping\n",
    "    column_mapping = {\n",
    "        'timestamp': 'timestamp',\n",
    "        'age': 'age',\n",
    "        'feeling sad or tearful': 'feeling_sad_or_tearful',\n",
    "        'irritable towards baby & partner': 'irritable_towards_baby_partner',\n",
    "        'trouble sleeping at night': 'trouble_sleeping_at_night',\n",
    "        'problems concentrating or making decision': 'problems_concentrating_or_making_decision',\n",
    "        'overeating or loss of appetite': 'overeating_or_loss_of_appetite',\n",
    "        'feeling anxious': 'label',\n",
    "        'feeling of guilt': 'feeling_of_guilt',\n",
    "        'problems of bonding with baby': 'problems_of_bonding_with_baby',\n",
    "        'suicide attempt': 'suicide_attempt'\n",
    "    }\n",
    "    \n",
    "    train_df = train_df.rename(columns=column_mapping)\n",
    "    test_df = test_df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Drop timestamp\n",
    "    train_df = train_df.drop(columns=['timestamp'])\n",
    "    test_df = test_df.drop(columns=['timestamp'])\n",
    "    \n",
    "    # Convert labels\n",
    "    label_mapping = {'Yes': 'Yes', 'No': 'No'}\n",
    "    train_df['label'] = train_df['label'].map(label_mapping).fillna('No')\n",
    "    test_df['label'] = test_df['label'].map(label_mapping).fillna('No')\n",
    "    \n",
    "    print(f\"Train label distribution:\\n{train_df['label'].value_counts()}\")\n",
    "    print(f\"Test label distribution:\\n{test_df['label'].value_counts()}\")\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_processing"
   },
   "source": [
    "## 4. Data Loading and Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df, test_df = load_and_preprocess_data(DATA_DIR)\n",
    "\n",
    "# Serialize to text\n",
    "print(\"\\nSerializing data to text...\")\n",
    "train_texts = [serialize_row(row, template) for _, row in train_df.iterrows()]\n",
    "test_texts = [serialize_row(row, template) for _, row in test_df.iterrows()]\n",
    "\n",
    "print(f\"\\nExample serialized text:\\n{train_texts[0]}\")\n",
    "print(f\"\\nLabel: {train_df.iloc[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_class"
   },
   "source": [
    "## 5. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset"
   },
   "outputs": [],
   "source": [
    "class PostpartumDataset(Dataset):\n",
    "    \"\"\"Dataset for postpartum depression classification\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Create input with task prefix\n",
    "        input_text = f\"classify: {text}\"\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize label\n",
    "        labels = self.tokenizer(\n",
    "            label,\n",
    "            max_length=10,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': labels['input_ids'].squeeze()\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize tokenizer\n",
    "print(\"Loading tokenizer and model...\")\n",
    "MODEL_NAME = \"t5-base\"  # Can use \"google/t5-v1_1-base\" or \"t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PostpartumDataset(\n",
    "    train_texts,\n",
    "    train_df['label'].tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = PostpartumDataset(\n",
    "    test_texts,\n",
    "    test_df['label'].tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_training"
   },
   "source": [
    "## 6. Model Fine-Tuning\n",
    "\n",
    "We'll use parameter-efficient fine-tuning similar to the TabLLM paper's IA3 approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_model"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model loaded on {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_args"
   },
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "OUTPUT_DIR = \"/content/tabllm_finetuned\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=5e-4,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    logging_steps=50,\n",
    "    eval_steps=100,\n",
    "    save_steps=200,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"FP16: {training_args.fp16}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trainer"
   },
   "outputs": [],
   "source": [
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train"
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Starting training...\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Training loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(f\"{OUTPUT_DIR}/final_model\")\n",
    "tokenizer.save_pretrained(f\"{OUTPUT_DIR}/final_model\")\n",
    "print(f\"Model saved to {OUTPUT_DIR}/final_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## 7. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict"
   },
   "outputs": [],
   "source": [
    "def predict_batch(model, tokenizer, texts, batch_size=16, device='cuda'):\n",
    "    \"\"\"Make predictions on a batch of texts\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        # Prepare inputs\n",
    "        inputs = [f\"classify: {text}\" for text in batch_texts]\n",
    "        encoded = tokenizer(\n",
    "            inputs,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "        \n",
    "        # Generate predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **encoded,\n",
    "                max_length=10,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        # Decode predictions\n",
    "        batch_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        predictions.extend(batch_preds)\n",
    "        \n",
    "        if (i // batch_size + 1) % 10 == 0:\n",
    "            print(f\"Processed {i+len(batch_texts)}/{len(texts)} samples\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Make predictions on test set\n",
    "print(\"Making predictions on test set...\")\n",
    "predictions = predict_batch(model, tokenizer, test_texts, device=device)\n",
    "\n",
    "# Convert predictions to binary\n",
    "def parse_prediction(pred):\n",
    "    pred = pred.strip().lower()\n",
    "    return 1 if 'yes' in pred else 0\n",
    "\n",
    "pred_binary = [parse_prediction(p) for p in predictions]\n",
    "true_binary = [1 if label == 'Yes' else 0 for label in test_df['label'].tolist()]\n",
    "\n",
    "print(f\"\\nExample predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"True: {test_df.iloc[i]['label']}, Predicted: {predictions[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "metrics"
   },
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_binary, pred_binary)\n",
    "precision = precision_score(true_binary, pred_binary, average='binary', zero_division=0)\n",
    "recall = recall_score(true_binary, pred_binary, average='binary', zero_division=0)\n",
    "f1 = f1_score(true_binary, pred_binary, average='binary', zero_division=0)\n",
    "\n",
    "try:\n",
    "    auc_roc = roc_auc_score(true_binary, pred_binary)\n",
    "except:\n",
    "    auc_roc = 0.5\n",
    "\n",
    "cm = confusion_matrix(true_binary, pred_binary)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TABLLM FINE-TUNING RESULTS - Postpartum Depression\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "print(f\"AUC-ROC:   {auc_roc:.4f} ({auc_roc*100:.2f}%)\")\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"TN: {cm[0][0]}, FP: {cm[0][1]}\")\n",
    "print(f\"FN: {cm[1][0]}, TP: {cm[1][1]}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(true_binary, pred_binary, target_names=['No Anxiety', 'Anxiety']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_results"
   },
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save"
   },
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "results = {\n",
    "    'model': MODEL_NAME,\n",
    "    'metrics': {\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'f1_score': float(f1),\n",
    "        'auc_roc': float(auc_roc)\n",
    "    },\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'classification_report': classification_report(true_binary, pred_binary, output_dict=True)\n",
    "}\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/finetuning_metrics.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'true_label': test_df['label'].tolist(),\n",
    "    'predicted_label': predictions,\n",
    "    'true_binary': true_binary,\n",
    "    'predicted_binary': pred_binary\n",
    "})\n",
    "predictions_df.to_csv(f\"{OUTPUT_DIR}/finetuning_predictions.csv\", index=False)\n",
    "\n",
    "print(f\"Results saved to {OUTPUT_DIR}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"- {OUTPUT_DIR}/final_model/ (trained model)\")\n",
    "print(f\"- {OUTPUT_DIR}/finetuning_metrics.json\")\n",
    "print(f\"- {OUTPUT_DIR}/finetuning_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 9. Download Results\n",
    "\n",
    "Download the results and model to your local machine or save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_files"
   },
   "outputs": [],
   "source": [
    "# Zip results for download\n",
    "!zip -r /content/tabllm_results.zip {OUTPUT_DIR}\n",
    "\n",
    "print(\"Results zipped!\")\n",
    "print(\"Download the file 'tabllm_results.zip' from the files panel\")\n",
    "\n",
    "# Or copy to Google Drive\n",
    "# !cp -r {OUTPUT_DIR} /content/drive/MyDrive/tabllm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Hyperparameter Tuning**: Experiment with different learning rates, batch sizes, and epochs\n",
    "2. **Model Size**: Try larger models like `t5-large` or `google/t5-v1_1-large` for better performance\n",
    "3. **Data Augmentation**: Generate synthetic samples to balance classes\n",
    "4. **Ensemble**: Combine multiple models for improved predictions\n",
    "5. **Error Analysis**: Examine misclassified samples to understand model limitations\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "- **Out of Memory**: Reduce batch size or use gradient accumulation\n",
    "- **Slow Training**: Ensure GPU runtime is enabled\n",
    "- **Poor Performance**: Try more epochs, different learning rate, or larger model\n",
    "\n",
    "## References\n",
    "\n",
    "- [TabLLM Paper](https://arxiv.org/pdf/2210.10723)\n",
    "- [TabLLM GitHub](https://github.com/clinicalml/TabLLM)\n",
    "- [T5 Paper](https://arxiv.org/abs/1910.10683)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
